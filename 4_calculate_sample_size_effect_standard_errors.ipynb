{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "085d12dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bff34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, scipy, time, warnings\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "from evaluation_framework.pipeline import EvaluationPipeline\n",
    "from evaluation_framework import steps as ef_steps\n",
    "from evaluation_framework.datasets import get_datasets_for_pattern\n",
    "from evaluation_framework.runners import run_on_many_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c25aa0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods.EF_std import calculate_std_on_dataset\n",
    "from methods.utils import calculate_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55587ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "692bb2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File folder with results, results will be stored here and loaded from there\n",
    "results_files_folder = 'sample_size_experiment_results'\n",
    "if not os.path.exists(results_files_folder):\n",
    "    os.makedirs(results_files_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb6a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4c23f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dataset = get_datasets_for_pattern(pattern=\"employment-2015_2016_2017_2018-CA.pq\", data_dir=\"datasets\")\n",
    "\n",
    "chunksizes = np.asarray([100,  200,  500, 1000, 2000, 5000])\n",
    "steps = np.minimum(chunksizes, 1000)\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "datasets = []\n",
    "for chunksize, step in zip(chunksizes, steps):\n",
    "    new_dataset = deepcopy(selected_dataset[0])\n",
    "    new_dataset.observations_in_chunk = chunksize\n",
    "    new_dataset.step_size = step\n",
    "    datasets.append(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fc3d88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "production    756392\n",
       "reference     376035\n",
       "train         374943\n",
       "Name: partition, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(selected_dataset[0].data_path)['partition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c14ee",
   "metadata": {},
   "source": [
    "# EF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4b839cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitored_models = [\n",
    "    'LogisticRegression_',\n",
    "    'LGBMClassifier_',\n",
    "    'RandomForestClassifier_',\n",
    "    'XGB_',\n",
    "    'FT_Transformer_',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af0aa948",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "\n",
    "for monitored_model in monitored_models:\n",
    "            experiments.append({\n",
    "                'method':'DATASET_STD',\n",
    "                'monitored_model': monitored_model,\n",
    "            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b007841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_df(dat, method, client_model):\n",
    "    res_data = dat[0]\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df['method'] = [method]\n",
    "    df['dataset'] = res_data['dataset_name']\n",
    "    df['monitored_model'] = [client_model]\n",
    "    df['chunksize'] = res_data['observations_in_chunk']\n",
    "    \n",
    "    df['std_accuracy'] = res_data['std_accuracy']\n",
    "    df['std_roc_auc'] = res_data['std_roc']\n",
    "    df['std_f1'] = res_data['std_f1']\n",
    "\n",
    "    \n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f83a10b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'method': 'DATASET_STD', 'monitored_model': 'LogisticRegression_'},\n",
       " {'method': 'DATASET_STD', 'monitored_model': 'LGBMClassifier_'},\n",
       " {'method': 'DATASET_STD', 'monitored_model': 'RandomForestClassifier_'},\n",
       " {'method': 'DATASET_STD', 'monitored_model': 'XGB_'},\n",
       " {'method': 'DATASET_STD', 'monitored_model': 'FT_Transformer_'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85f523f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "524cea3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 0 out of 5\n",
      "PROGRESS: 0.0\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 100, all chunks: 11324, reference_chunks: 3760, transition chunks: 1, production_chunks (includes transition) :7564\n",
      "PROGRESS: 0.03333333333333333\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 200, all chunks: 5662, reference_chunks: 1880, transition chunks: 1, production_chunks (includes transition) :3782\n",
      "PROGRESS: 0.06666666666666667\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 500, all chunks: 2264, reference_chunks: 752, transition chunks: 1, production_chunks (includes transition) :1512\n",
      "PROGRESS: 0.09999999999999999\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 1000, all chunks: 1132, reference_chunks: 376, transition chunks: 1, production_chunks (includes transition) :756\n",
      "PROGRESS: 0.13333333333333333\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 2000, all chunks: 1131, reference_chunks: 375, transition chunks: 2, production_chunks (includes transition) :756\n",
      "PROGRESS: 0.16666666666666666\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 5000, all chunks: 1128, reference_chunks: 372, transition chunks: 5, production_chunks (includes transition) :756\n",
      "experiment 1 out of 5\n",
      "PROGRESS: 0.19999999999999998\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 100, all chunks: 11324, reference_chunks: 3760, transition chunks: 1, production_chunks (includes transition) :7564\n",
      "PROGRESS: 0.2333333333333333\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 200, all chunks: 5662, reference_chunks: 1880, transition chunks: 1, production_chunks (includes transition) :3782\n",
      "PROGRESS: 0.26666666666666666\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 500, all chunks: 2264, reference_chunks: 752, transition chunks: 1, production_chunks (includes transition) :1512\n",
      "PROGRESS: 0.3\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 1000, all chunks: 1132, reference_chunks: 376, transition chunks: 1, production_chunks (includes transition) :756\n",
      "PROGRESS: 0.3333333333333333\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 2000, all chunks: 1131, reference_chunks: 375, transition chunks: 2, production_chunks (includes transition) :756\n",
      "PROGRESS: 0.3666666666666667\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 5000, all chunks: 1128, reference_chunks: 372, transition chunks: 5, production_chunks (includes transition) :756\n",
      "experiment 2 out of 5\n",
      "PROGRESS: 0.39999999999999997\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 100, all chunks: 11324, reference_chunks: 3760, transition chunks: 1, production_chunks (includes transition) :7564\n",
      "PROGRESS: 0.43333333333333335\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 200, all chunks: 5662, reference_chunks: 1880, transition chunks: 1, production_chunks (includes transition) :3782\n",
      "PROGRESS: 0.4666666666666666\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 500, all chunks: 2264, reference_chunks: 752, transition chunks: 1, production_chunks (includes transition) :1512\n",
      "PROGRESS: 0.5\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 1000, all chunks: 1132, reference_chunks: 376, transition chunks: 1, production_chunks (includes transition) :756\n",
      "PROGRESS: 0.5333333333333333\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 2000, all chunks: 1131, reference_chunks: 375, transition chunks: 2, production_chunks (includes transition) :756\n",
      "PROGRESS: 0.5666666666666667\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 5000, all chunks: 1128, reference_chunks: 372, transition chunks: 5, production_chunks (includes transition) :756\n",
      "experiment 3 out of 5\n",
      "PROGRESS: 0.6\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 100, all chunks: 11324, reference_chunks: 3760, transition chunks: 1, production_chunks (includes transition) :7564\n",
      "PROGRESS: 0.6333333333333333\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 200, all chunks: 5662, reference_chunks: 1880, transition chunks: 1, production_chunks (includes transition) :3782\n",
      "PROGRESS: 0.6666666666666666\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 500, all chunks: 2264, reference_chunks: 752, transition chunks: 1, production_chunks (includes transition) :1512\n",
      "PROGRESS: 0.7000000000000001\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 1000, all chunks: 1132, reference_chunks: 376, transition chunks: 1, production_chunks (includes transition) :756\n",
      "PROGRESS: 0.7333333333333334\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 2000, all chunks: 1131, reference_chunks: 375, transition chunks: 2, production_chunks (includes transition) :756\n",
      "PROGRESS: 0.7666666666666666\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 5000, all chunks: 1128, reference_chunks: 372, transition chunks: 5, production_chunks (includes transition) :756\n",
      "experiment 4 out of 5\n",
      "PROGRESS: 0.7999999999999999\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 100, all chunks: 11324, reference_chunks: 3760, transition chunks: 1, production_chunks (includes transition) :7564\n",
      "PROGRESS: 0.8333333333333334\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 200, all chunks: 5662, reference_chunks: 1880, transition chunks: 1, production_chunks (includes transition) :3782\n",
      "PROGRESS: 0.8666666666666667\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 500, all chunks: 2264, reference_chunks: 752, transition chunks: 1, production_chunks (includes transition) :1512\n",
      "PROGRESS: 0.9\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 1000, all chunks: 1132, reference_chunks: 376, transition chunks: 1, production_chunks (includes transition) :756\n",
      "PROGRESS: 0.9333333333333332\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 2000, all chunks: 1131, reference_chunks: 375, transition chunks: 2, production_chunks (includes transition) :756\n",
      "PROGRESS: 0.9666666666666667\n",
      "\n",
      "Evaluating on: datasets\\employment-2015_2016_2017_2018-CA.pq\n",
      "Chunk size: 5000, all chunks: 1128, reference_chunks: 372, transition chunks: 5, production_chunks (includes transition) :756\n",
      "CPU times: total: 8min 42s\n",
      "Wall time: 8min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "experiments_done = []\n",
    "experiments_to_rerun = []\n",
    "\n",
    "for i, experiment in enumerate(experiments[:]):\n",
    "    \n",
    "    print(\"experiment {} out of {}\".format(i, len(experiments)))\n",
    "    for j, dataset in enumerate(datasets[:]):\n",
    "        print(\"PROGRESS: \" + str((i*len(datasets)+j)/len(experiments)/len(datasets)))\n",
    "        OBSERVATIONS_IN_CHUNK = dataset.observations_in_chunk\n",
    "    \n",
    "        method = experiment['method']\n",
    "        monitored_model = experiment['monitored_model']\n",
    "\n",
    "        full_name = '_'.join((method, monitored_model))\n",
    "\n",
    "        calculation_step = ef_steps.Step(description='Calculate STD', \n",
    "                     func=calculate_std_on_dataset, args=(monitored_model, OBSERVATIONS_IN_CHUNK, 500)) # custom step\n",
    "\n",
    "\n",
    "        pipeline = EvaluationPipeline(steps=[\n",
    "            ef_steps.SplitDataStep(), #split raw to train test (reference/analysis)\n",
    "            ef_steps.CombineProcessedReferenceProductionWithRawStep(), # combine after processing\n",
    "            ef_steps.SplitIntoChunksStep(), # split to chunks\n",
    "            ef_steps.Step(description='Calculate targets', \n",
    "                     func=calculate_targets, args=(monitored_model, )), # custom step\n",
    "            calculation_step,\n",
    "            ])\n",
    "\n",
    "        res, dat = run_on_many_datasets(datasets=[dataset], pipeline=pipeline, log_metrics=False,)\n",
    "        \n",
    "        \n",
    "        if \"traceback\" in dat[0].keys():\n",
    "            experiments_to_rerun.append((experiment, dataset.data_path, dat[0]['traceback']))\n",
    "        else:\n",
    "            df_results = save_results_to_df(dat, method, monitored_model)\n",
    "            results.append(df_results)\n",
    "            \n",
    "        experiments_done.append(experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc073cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(results).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc5022ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>monitored_model</th>\n",
       "      <th>chunksize</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>std_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LogisticRegression_</td>\n",
       "      <td>100</td>\n",
       "      <td>0.038775</td>\n",
       "      <td>0.032782</td>\n",
       "      <td>0.045941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LogisticRegression_</td>\n",
       "      <td>200</td>\n",
       "      <td>0.028699</td>\n",
       "      <td>0.024903</td>\n",
       "      <td>0.032665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LogisticRegression_</td>\n",
       "      <td>500</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.019808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LogisticRegression_</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>0.011328</td>\n",
       "      <td>0.015079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LogisticRegression_</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.010864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LogisticRegression_</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.006470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LGBMClassifier_</td>\n",
       "      <td>100</td>\n",
       "      <td>0.037842</td>\n",
       "      <td>0.030206</td>\n",
       "      <td>0.043526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LGBMClassifier_</td>\n",
       "      <td>200</td>\n",
       "      <td>0.028895</td>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.033803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LGBMClassifier_</td>\n",
       "      <td>500</td>\n",
       "      <td>0.017623</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.019956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LGBMClassifier_</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.014224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LGBMClassifier_</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.008262</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.009531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>LGBMClassifier_</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.006534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>RandomForestClassifier_</td>\n",
       "      <td>100</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>0.052690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>RandomForestClassifier_</td>\n",
       "      <td>200</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>0.023937</td>\n",
       "      <td>0.034374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>RandomForestClassifier_</td>\n",
       "      <td>500</td>\n",
       "      <td>0.017396</td>\n",
       "      <td>0.015476</td>\n",
       "      <td>0.021522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>RandomForestClassifier_</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0.014788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>RandomForestClassifier_</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>0.011207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>RandomForestClassifier_</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.006843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>XGB_</td>\n",
       "      <td>100</td>\n",
       "      <td>0.038768</td>\n",
       "      <td>0.029833</td>\n",
       "      <td>0.046398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>XGB_</td>\n",
       "      <td>200</td>\n",
       "      <td>0.027775</td>\n",
       "      <td>0.022486</td>\n",
       "      <td>0.032382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>XGB_</td>\n",
       "      <td>500</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.013325</td>\n",
       "      <td>0.019153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>XGB_</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.014527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>XGB_</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.006067</td>\n",
       "      <td>0.009685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>XGB_</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.006337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>FT_Transformer_</td>\n",
       "      <td>100</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>0.053371</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>FT_Transformer_</td>\n",
       "      <td>200</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.039113</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>FT_Transformer_</td>\n",
       "      <td>500</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>0.024031</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>FT_Transformer_</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.015371</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>FT_Transformer_</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.010573</td>\n",
       "      <td>0.012426</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DATASET_STD</td>\n",
       "      <td>employment-2015_2016_2017_2018-CA.pq</td>\n",
       "      <td>FT_Transformer_</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         method                               dataset  \\\n",
       "0   DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "1   DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "2   DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "3   DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "4   DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "5   DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "6   DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "7   DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "8   DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "9   DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "10  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "11  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "12  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "13  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "14  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "15  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "16  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "17  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "18  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "19  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "20  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "21  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "22  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "23  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "24  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "25  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "26  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "27  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "28  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "29  DATASET_STD  employment-2015_2016_2017_2018-CA.pq   \n",
       "\n",
       "            monitored_model  chunksize  std_accuracy  std_roc_auc    std_f1  \n",
       "0       LogisticRegression_        100      0.038775     0.032782  0.045941  \n",
       "1       LogisticRegression_        200      0.028699     0.024903  0.032665  \n",
       "2       LogisticRegression_        500      0.017593     0.015622  0.019808  \n",
       "3       LogisticRegression_       1000      0.012887     0.011328  0.015079  \n",
       "4       LogisticRegression_       2000      0.009353     0.008029  0.010864  \n",
       "5       LogisticRegression_       5000      0.005681     0.004864  0.006470  \n",
       "6           LGBMClassifier_        100      0.037842     0.030206  0.043526  \n",
       "7           LGBMClassifier_        200      0.028895     0.022149  0.033803  \n",
       "8           LGBMClassifier_        500      0.017623     0.013491  0.019956  \n",
       "9           LGBMClassifier_       1000      0.011936     0.009819  0.014224  \n",
       "10          LGBMClassifier_       2000      0.008262     0.006446  0.009531  \n",
       "11          LGBMClassifier_       5000      0.005697     0.004322  0.006534  \n",
       "12  RandomForestClassifier_        100      0.041945     0.036789  0.052690  \n",
       "13  RandomForestClassifier_        200      0.029230     0.023937  0.034374  \n",
       "14  RandomForestClassifier_        500      0.017396     0.015476  0.021522  \n",
       "15  RandomForestClassifier_       1000      0.012400     0.010830  0.014788  \n",
       "16  RandomForestClassifier_       2000      0.009241     0.007805  0.011207  \n",
       "17  RandomForestClassifier_       5000      0.005708     0.004875  0.006843  \n",
       "18                     XGB_        100      0.038768     0.029833  0.046398  \n",
       "19                     XGB_        200      0.027775     0.022486  0.032382  \n",
       "20                     XGB_        500      0.016757     0.013325  0.019153  \n",
       "21                     XGB_       1000      0.012569     0.009916  0.014527  \n",
       "22                     XGB_       2000      0.008340     0.006067  0.009685  \n",
       "23                     XGB_       5000      0.005413     0.004124  0.006337  \n",
       "24          FT_Transformer_        100      0.045990     0.053371  0.000000  \n",
       "25          FT_Transformer_        200      0.036802     0.039113  0.000000  \n",
       "26          FT_Transformer_        500      0.021960     0.024031  0.000000  \n",
       "27          FT_Transformer_       1000      0.015371     0.016614  0.000000  \n",
       "28          FT_Transformer_       2000      0.010573     0.012426  0.000000  \n",
       "29          FT_Transformer_       5000      0.006950     0.007716  0.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a581873a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024_05_21_12_23_27'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb91bc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample_size_experiment_results'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_files_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3157c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(os.path.join(results_files_folder, 'STD_results.pq'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bda2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c80eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72d60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NMLp39",
   "language": "python",
   "name": "nmlp39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
